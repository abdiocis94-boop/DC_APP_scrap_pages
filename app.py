import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import plotly.express as px
import json
import time
import os

# Configuration de la page
st.set_page_config(
    page_title="CoinAfrique Scraper",
    page_icon="üëï",
    layout="wide"
)

# Cr√©er les dossiers n√©cessaires
os.makedirs("evaluations", exist_ok=True)

# Initialisation session
if 'scraped_data' not in st.session_state:
    st.session_state.scraped_data = None
if 'cleaned_data' not in st.session_state:
    st.session_state.cleaned_data = None

# ============================================
# FONCTIONS DE BASE
# ============================================

def scraping_safe(url, pages=3):
    """Fonction de scraping s√©curis√©e"""
    all_data = []
    
    for page_num in range(1, pages + 1):
        try:
            page_url = f"{url}?page={page_num}" if "?" not in url else f"{url}&page={page_num}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(page_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                containers = soup.find_all('div', {'class': 'col s6 m4 l3'})
                
                for container in containers:
                    try:
                        title_elem = container.find('p', {'class': 'ad__card-description'})
                        price_elem = container.find('p', {'class': 'ad__card-price'})
                        location_elem = container.find('p', {'class': 'ad__card-location'})
                        img_elem = container.find('img', {'class': 'ad__card-img'})
                        
                        if all([title_elem, price_elem, location_elem, img_elem]):
                            item = {
                                'titre': title_elem.a.text.strip() if title_elem.a else 'Non sp√©cifi√©',
                                'prix': price_elem.a.text.strip() if price_elem.a else '0 CFA',
                                'localisation': location_elem.span.text.strip() if location_elem.span else 'Non sp√©cifi√©e',
                                'image': img_elem.get('src', ''),
                                'page': page_num,
                                'date_scraping': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                'url_source': url
                            }
                            all_data.append(item)
                    except:
                        continue
                
                time.sleep(2)  # Respect du serveur
            else:
                st.warning(f"Page {page_num}: Statut {response.status_code}")
                
        except Exception as e:
            st.error(f"Erreur page {page_num}: {str(e)}")
            break
    
    return pd.DataFrame(all_data) if all_data else pd.DataFrame()

# ============================================
# INTERFACE STREAMLIT
# ============================================

def main():
    st.sidebar.title("üëï CoinAfrique Scraper")
    
    menu = st.sidebar.radio(
        "Navigation",
        ["üè† Accueil", "üîç Scraper", "üì• T√©l√©charger", "üìä Dashboard", "‚≠ê √âvaluation"]
    )
    
    # Page d'accueil
    if menu == "üè† Accueil":
        st.title("CoinAfrique Scraper")
        st.markdown("""
        ### Application de scraping et d'analyse de donn√©es
        
        **Fonctionnalit√©s :**
        1. üîç Scraping multi-pages depuis CoinAfrique
        2. üì• Export des donn√©es en CSV/JSON
        3. üìä Dashboard interactif
        4. ‚≠ê Formulaire d'√©valuation
        """)
        
        # URLs de test
        st.info("""
        **URLs disponibles :**
        - https://sn.coinafrique.com/categorie/vetements-homme/
        - https://sn.coinafrique.com/categorie/telephones
        - https://sn.coinafrique.com/categorie/ordinateurs
        """)
    
    # Page de scraping
    elif menu == "üîç Scraper":
        st.title("üîç Scraper des Donn√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            url = st.text_input(
                "URL √† scraper",
                value="https://sn.coinafrique.com/categorie/telephones"
            )
        
        with col2:
            pages = st.slider("Nombre de pages", 1, 5, 2)
        
        if st.button("üöÄ Lancer le scraping", type="primary"):
            with st.spinner("Scraping en cours..."):
                df = scraping_safe(url, pages)
                
                if not df.empty:
                    st.session_state.scraped_data = df
                    st.success(f"‚úÖ {len(df)} annonces trouv√©es !")
                    
                    # Aper√ßu
                    st.dataframe(df, use_container_width=True)
                else:
                    st.warning("Aucune donn√©e trouv√©e. Essayez une autre URL.")
    
    # Page de t√©l√©chargement
    elif menu == "üì• T√©l√©charger":
        st.title("üì• T√©l√©charger les Donn√©es")
        
        if st.session_state.scraped_data is not None:
            df = st.session_state.scraped_data
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Annonces", len(df))
            
            with col2:
                st.metric("Colonnes", len(df.columns))
            
            # Format CSV
            csv = df.to_csv(index=False)
            st.download_button(
                label="üì• T√©l√©charger CSV",
                data=csv,
                file_name=f"scraping_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
            
            # Format JSON
            json_str = df.to_json(orient='records', indent=2)
            st.download_button(
                label="üì• T√©l√©charger JSON",
                data=json_str,
                file_name=f"scraping_{datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json"
            )
            
            st.dataframe(df, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible. Scrapez d'abord des donn√©es.")
    
    # Page Dashboard
    elif menu == "üìä Dashboard":
        st.title("üìä Dashboard")
        
        if st.session_state.scraped_data is not None:
            df = st.session_state.scraped_data
            
            # Nettoyage simple
            if 'prix' in df.columns:
                # Extraire les valeurs num√©riques des prix
                df['prix_numerique'] = df['prix'].str.extract(r'(\d+)').astype(float)
            
            # M√©triques
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total annonces", len(df))
            
            with col2:
                if 'prix_numerique' in df.columns:

                    avg
